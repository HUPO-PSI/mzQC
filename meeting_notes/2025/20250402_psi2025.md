# HUPO-PSI Spring Meeting 2025: QC Working Group

Tübingen, Germany
April 2–3, 2025

Attendees:

* Wout Bittremieux
* Dave Tabb
* Julian Uszkoreit
* Thomas Payne
* Yasin El Abiead
* Bo Burla
* Sergio Legaz
* Sang Won Lee
* Soyon Park
* Yanting Chok
* John Park
* Nils Hoffmann
* Helge Hecht
* Johannes Rainer
* Philippine Louail

---

## Materials & links

* Official website: [https://hupo-psi.github.io/mzQC/](https://hupo-psi.github.io/mzQC/) 
  * mzQC introduction: [https://hupo-psi.github.io/mzQC/mzQC-intro/](https://hupo-psi.github.io/mzQC/mzQC-intro/) 
  * mzQC for analytical chemists: [https://hupo-psi.github.io/mzQC/use-cases/analytical-chemists/](https://hupo-psi.github.io/mzQC/use-cases/analytical-chemists/)
  * mzQC use cases: [https://hupo-psi.github.io/mzQC/use-cases/](https://hupo-psi.github.io/mzQC/use-cases/)  
* Working group GitHub (standard specification): [https://github.com/HUPO-PSI/mzQC](https://github.com/HUPO-PSI/mzQC) 
* MS Quality Hub (software implementations): [https://github.com/MS-Quality-Hub/](https://github.com/MS-Quality-Hub/)

## Introduction to mzQC

* mzQC file structure
  * JSON-based file format.
  * Supports both run-level (runQualities) and set-level (setQualities) metrics.
  * Can include input file references, analysis software used, controlled vocabulary (CV) terms, and other contextual metadata.
* Controlled vocabulary (CV) and schema
  * Every metric or field is defined via CV terms (e.g., PSI-MS CV).
  * Ensures machine-readability and semantic clarity.
* Granularity of QC metrics: QC can be performed at multiple levels: individual spectra, LC-MS runs, and experimental sets.
* Overview of examples and use cases on the mzQC website.

## Semantic validation profiles

* Proposed concept to define minimal and recommended metadata fields for specific use cases (e.g., metabolomics vs. proteomics).
* Can enforce field presence, CV use, and validation rules.
* Still under development; useful for repositories and standard-compliant workflows.
* **Action item:** Explore integration of semantic validation profiles similar to mzTab-M approaches.

## Interpretation and thresholding

* Emphasized that QC metrics are context-dependent—not inherently “good” or “bad.”
* Thresholds and interpretations are user-defined.
* Tools can aggregate and visualize trends over time (e.g., Shewhart control charts).

## Tool support

* Tools like QuaMeter, PTXQC, and others support mzQC export.
* APIs exist in several languages.
* No unified end-to-end pipeline yet; current workflows require manual integration.
* **Action item:** Consider building example pipelines from raw data to final output combining QC tools with mzQC export.
* Abandonware: Discussion about outdated/unsupported tools (e.g., SwaMe, Prognosticator). Focus should shift toward better-supported and published tools.

## Adoption and community engagement

* Emphasis on the need to lower the learning curve via better documentation and beginner-friendly materials.
* Noted the need to make QC more accessible for new researchers.
* Sometimes resistance from users to share QC metrics (misunderstandings, perceived competitiveness).
* **Action item:** Develop beginner-friendly documentation and examples for mzQC.
* **Action item:** Currently, no general-purpose mzQC visualizer is available. We should develop a plug-and-play web viewer, potentially through Google Summer of Code.
  * Feature request: Export specific QC metric(s) of interest.
* Further developing the Skyline plugin for mzQC export could be a student project.

## mzQC developer documentation

* Need for better guidance on writing mzQC files, especially for developers.
* **Action items:** Provide fully functional code examples using the software libraries for developers.
  * Add code snippets and starter templates.
  * Include practical examples (e.g., generating metrics using Python).
  * Improve visibility of tutorials and documentation on the website.

## Integration of mzQC with other standards

* SDRF: Importance of metadata (e.g., replicate grouping) in accurate QC metrics.
* mzTab/mzTab-M: Linking datasets (e.g., raw + feature table) via mzQC for better interpretability.
* Demonstrate how these formats synergize to create an ecosystem of powerful tools.

## Practical examples & community contributions

* Reviewed video from Manchester lab showcasing live QC display (via Raspberry Pi + TV).
* Highlights importance of real-time monitoring and visible QC feedback loops.
* **Action item:** Prominently feature such examples on the mzQC website.
* **Action item:** Create an overview of publications that use mzQC and success stories.

## Repository-scale QC

* Integrating QC metadata into public repositories (e.g., PRIDE, GNPS).
  * The GNPS, MetaboLights, and Metabolomics Workbench teams have already been computing several metrics for metabolomics data in these repositories.
  * **Action item:** Explore how these data can be converted into mzQC and provided through a filterable web interface (external from the repositories).
* Filterable datasets based on QC metrics (mzQC) and experimental metadata (e.g., via SDRF).
* Emphasis on gradual build-up starting from key datasets.
* **Action item:** Idea to use repository-scale QC metrics as a hackathon project. Submit this to the [ELIXIR BioHackathon](https://elixir-europe.org/events/biohackathon-europe) (Berlin; November 3–7, 2025).
  * Goal: implement rudimentary mzQC (+ mzTab) export pipelines for data in PRIDE that has SDRF.
  * Example for MetaboLights (targeted lipidomics) in Java: [Jupyter notebook link](https://nbviewer.org/github/nilshoffmann/jmzqc-usecase/blob/main/jmzqc_lipidomics_demo.ipynb)
  * Example for a MassIVE dataset (single file) in Java: [Jupyter notebook link](https://nbviewer.org/github/nilshoffmann/jmzqc-usecase/blob/main/jmzqc_proteomics_demo.ipynb)

## mzQC specification updates (v1.1)

* Need for minor non-backward-compatible changes:
  * Add softwareSettings to analysisSoftware object.
  * Support matrix-style metrics with row/column labels (decoupled from the matrix values).
* Plan to update JSON schema to official standard (2020-12).
* Discussed strategy for merging mzQC files from multiple tools. Don’t overcomplicate this.

* Current location of the specification document: Hosted on GitHub; considered vulnerable to change or deletion.
* **Action item:** Mirror the specification on Zenodo to obtain a DOI, enabling immutability and easy citation in manuscripts.

## Controlled vocabulary (CV) updates

* Draft CV terms needed for TD-Auditor and DIAmetric tools.
* **Action items:**
  * Finalize metric definitions for new tools.
  * Add software and algorithm references to CV.
* Avoid duplicate metrics; identify unique ones needing new accessions.

## QC metrics in commercial tools

* Presentation from Bruker (Twinscape):
  * Real-time monitoring of instrument health (e.g., chiller temperature, turbo pump power).
  * Use of ML to predict failures and trigger service tickets.
  * QC integration across five data types: instrument health, diagnostics, system performance, stability, QC.
* Suggestion to allow importing mzQC files into Twinscape for enhanced integration.
* Emphasis on user-defined thresholds due to variability in protocols.

---

## mzQC manuscript planning and use case review

* The manuscript introduces mzQC as a standardized format for QC in mass spectrometry.
* Two primary manuscript components:
  * Accessible format description: What is mzQC, how is it structured, and why it's needed.
  * Demonstration of mzQC's value through diverse use cases.

**Use case 1: Outlier detection in _Mycobacterium tuberculosis_**

* Dataset: 120 MTb runs.
* Tools used: QuaMeter (ID-free), Wout’s outlier detection, PCA approach.
* Goal: Flag outliers, assess variation across methods.
* Findings: Unreported instrument failure led to performance decay.
* Status: Near-final; interpretation of QC dimensions still needed.

**Use case 2: Longitudinal instrument monitoring**

* Data source: CPTAC system suitability data
* Tools used: Skyline → mzQC → MSstatsQC.
* Focus: Instrument stability over time using targeted proteomics data.
* Status: Essentially complete.

**Use case 3: Clinical lipidomics**

* Comprehensive QC setup: injection protocols, response curves, dilution, long-term reference samples.
* In-house software exports QC metrics as CSV/Excel and S4 objects.
* Action Items:
  * Export QC data to mzQC format.
  * Define and document all relevant metrics.
  * Improve clustering visualizations (e.g., by block color coding).

**Use case 4: DIA proteomics**

* Software: DIAmetric.
* Capabilities: SWATH definitions, TIC retention time, scan intervals.
* Status: Metrics finalized; export to mzQC and CV term definitions pending.
* Action: Provide metric list and figures for manuscript.

**Use case 5: Repository-scale untargeted metabolomics**

* Data volume: 700,000–800,000 MS runs from GNPS. MetaboLights, Metabolomics Workbench.
* Metrics: Basic MS1/MS2 scan counts, positive/negative mode, annotations.
* Storage: SQLite and TSV files.
* **Action items:**
  * Convert metrics to mzQC.
  * Confirm with GNPS/Workbench collaborators about inclusion.
  * Possibly share data via Zenodo.

**Potential additional use cases**

* Johannes could contribute an additional use case on untargeted metabolomics.
* Helge will look into adding MsQuality support in Galaxy.

## Manuscript structure and submission plans

* Target journals: *Nature Methods* (pre-submission inquiry), *Nature Communications*, *Analytical Chemistry*
* Goal: Submit manuscript by early summer 2025.
* Authorship:
  * First author: Mathias, shared with Chris and Nils.
  * Senior author: Wout and Dave.
  * Broad co-authorship due to longstanding community effort.

## Additional discussions and suggestions

* Protocol paper: Consider a follow-up protocol publication (e.g., *Current Protocols in Bioinformatics*) detailing end-to-end QC application.
* Long-term goal to support online QC run filtering across repositories using mzQC data.

## Technical and CV term development

* Each tool/use case must:
  * Export QC data to mzQC.
  * Check existing CV terms for reusability.
  * Propose new CV terms as needed, using GitHub issue templates.
  * One GitHub issue per new CV term is preferred for clarity.
* Emphasis on rigor and clarity in metric definitions to improve interoperability and reproducibility.

## Group structure and leadership

* Co-chair: Need to confirm whether Mathias remains engaged as co-chair. YES.
* Other roles:
  * Secretary: Currently unfilled, but no urgency to appoint one.
  * Ontology coordinator: Julian agreed to retake this official role.
  * Updates to affiliations (e.g., Dave now at University Medical Center Groningen).

## Current and new goals of the working group

* Ongoing projects:
  * mzQC file format maintenance.
  * CV development.
  * Software libraries and integration.
  * Diverse use cases to demonstrate mzQC benefits.
* New proposed milestones:
  * Develop analysis and visualization tools tailored for mzQC, to enable intuitive interpretation and reporting of quality control metrics.
  * Supplement prominent mass spectrometry-based biological studies with mzQC quality metrics, to improve transparency and reproducibility.
  * Support the inclusion of mzQC information as part of public data submissions to widely used mass spectrometry data repositories, enhancing data quality tracking and reuse.

## Future vision and roadmap

* Beyond manuscript publication:
  * Avoid entering “maintenance mode”; aim to maintain momentum.
  * Publish new papers every 2–3 years (e.g., on success stories or advanced applications of mzQC).
* Conferences: Engage through workshops (e.g., past ASMS quality control workshop).

## Applications and impact

* Two directions: Using AI for QC (e.g., predictive diagnostics, trend detection) vs using QC to enable AI (e.g., filtering training data).
  * Decision support for labs:
    * QC can serve as a decision-support tool for instrument maintenance and experiment quality assurance.
    * Examples discussed: calibration drift, mass error tracking, variability due to inconsistent methods.
  * For AI researchers:
    * mzQC can help AI researchers identify high-quality training data.
    * Enables filtering of datasets based on quality metrics like CVs.
    * Decided to frame goal #6 to also implicitly support AI applications through better QC metadata in repositories, without overcommitting to AI work as a core responsibility of the group.
* Repository-scale QC:
  * Long-term vision for system-wide QC integration across datasets.
  * Proof-of-concept planned on selected prominent datasets.
* Collaboration opportunities: Suggestion to contact national repositories (e.g., Spain) and standardize metadata and QC practices.
